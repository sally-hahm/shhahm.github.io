---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About Me  

I am **Seung-Hyun Hahm**, a **4th-year undergraduate majoring in Computer Science and Neuroscience**, passionate about **Artificial General Intelligence (AGI) and Embodied AI**. My research focuses on **developing AI that can interact with and adapt to the real world**, moving beyond static datasets and pre-programmed behaviors.  

I believe that **AI should be designed with people in mind**â€”not just for efficiency, but for **accessibility, adaptability, and real-world usability**. My work lies at the intersection of **machine learning, neuroscience, and human-computer interaction**, where I explore **how AI can reason, learn, and assist individuals in meaningful ways**.  

Currently, I am conducting **AI research at Dartmouth**, focusing on **multimodal learning and AI-generated assistive technologies**, while also applying my skills to **industry settings through startup and blockchain-driven AI projects**.  

---

## **My Approach to AI Research**  
My research philosophy is shaped by three core values:  

### **ðŸ”¹ I Embrace Challenges â€“ Bridging AI Research and Industry Applications**  
Some of the **most valuable insights** come from stepping outside of structured environments. Thatâ€™s why I took an **unconventional path**, gaining hands-on experience in **startups and industry research** to work on **scalable, real-world AI applications**.  

At **NextCare**, I helped develop **AI-driven privacy-preserving healthcare systems**, balancing **security, scalability, and real-world usability**. At **dKargo**, I led a team working on **large-scale blockchain integration for AI-driven logistics**, ensuring models were **adaptive, efficient, and applicable beyond controlled research settings**.  

These experiences reinforced my belief that **research is most impactful when applied to real challenges**â€”**AGI and Embodied AI should not be confined to theoretical development but actively interact with dynamic human environments**.  

---

### **ðŸ”¹ I Think in Other Peopleâ€™s Shoes â€“ AI for Accessibility & Human-Centered AI**  
Technology should be **built for people, not just for efficiency**. My research is deeply rooted in **human-computer interaction (HCI) and AI accessibility**, ensuring that AI models **serve diverse user needs rather than reinforcing existing limitations**.  

For example, I developed a **patented tactile guidance system for visually impaired individuals**, which provides **sensory navigation cues in public spaces**. Similarly, in my AI research, I work on **multimodal AI-generated audio descriptions**, enhancing **emotion, context, and usability in assistive technologies**.  

By combining **human-computer interaction (HCI) with machine learning**, I aim to build **AI that understands users beyond static datasets and optimizes itself for real-world adaptability**.  

---

### **ðŸ”¹ I Build AI That Interacts With the Real World â€“ AGI & Embodied AI Research**  
The future of AI isnâ€™t just about larger modelsâ€”itâ€™s about **real-world interaction and adaptability**. My research goal is to develop AI that can **reason, plan, and learn from real-time experiences** rather than relying solely on predefined training data.  

At Dartmouth, I am currently working on **AI-generated multimodal models for real-time audio descriptions**, exploring **how AI can interpret and convey complex human experiences** dynamically. My work in **reinforcement learning and adaptive AI decision-making** focuses on how AI can **process real-time sensory inputs, predict long-term outcomes, and make intelligent adjustments based on human behavior**.  

To me, **AGI should be more than just a predictive modelâ€”it should be an interactive system that continuously refines itself through engagement with the world**.  

---

## **Research Interests**  
- **Embodied AI & Adaptive Learning** â€“ AI that interacts with the environment rather than relying solely on pre-trained data.  
- **Multimodal Learning** â€“ Integrating **text, vision, sound, and movement** for holistic AI decision-making.  
- **Human-Computer Interaction & AI for Accessibility** â€“ AI-driven assistive technologies for visually and mobility-impaired individuals.  
- **AGI & Reinforcement Learning** â€“ Long-horizon AI planning, adaptive reasoning, and self-improving systems.  

---

## **Contact**  
I am always open to **collaborations, research discussions, and AI projects focused on accessibility, human-computer interaction, and embodied AI**.  

ðŸ“Œ **LinkedIn:** [Seung-Hyun Hahm LinkedIn](https://www.linkedin.com/in/seung-hyun-hahm/)  
ðŸ“Œ **GitHub:** [Your GitHub Link]  
ðŸ“Œ **Email:** [Your Email]  

Feel free to reach out! ðŸš€  
